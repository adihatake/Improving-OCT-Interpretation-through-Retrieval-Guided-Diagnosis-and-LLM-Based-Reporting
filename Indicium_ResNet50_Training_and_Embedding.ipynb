{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adihatake/Improving-OCT-Interpretation-through-Retrieval-Guided-Diagnosis-and-LLM-Based-Reporting/blob/main/Indicium_ResNet50_Training_and_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TpcUDq2lvro"
      },
      "source": [
        "# README!\n",
        "**Cells required to execute:**\n",
        "1. Load the dependencies\n",
        "2. Load datasets from dis\n",
        "3. Preprocess the data\n",
        "4. Define the model\n",
        "\n",
        "**For Inference:**\n",
        "A model must be trained or loaded locally from your disk. Once this has been done, execute the \"inspect an example\" cell\n",
        "\n",
        "**For FAISS Retrieval**\n",
        "A FAISS index must be created or loaded locally from your disk. Execute the \"make a FAISS query\" to make a retrieval.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVKQMv7n5RXC"
      },
      "source": [
        "# Load dependencies\n",
        "Takes a couple minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo0Fg9CRYF0x",
        "outputId": "3448ee3b-5658-4c96-ecb7-a31fc3191e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MT8Fz5UyIanc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mbWXNbjUA1eh"
      },
      "outputs": [],
      "source": [
        "! pip install -U datasets\n",
        "! pip install faiss-cpu\n",
        "! pip install langchain-community\n",
        "! pip install -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ghv41nJiv_Rt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import datasets\n",
        "import numpy as np\n",
        "import random\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from datasets import load_dataset, load_from_disk\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.embeddings import Embeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F82eGeoryGep"
      },
      "source": [
        "# Load datasets from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TJ-ginAppGfC"
      },
      "outputs": [],
      "source": [
        "# Load datasets locally\n",
        "raw_train_data = load_dataset(\"parquet\", data_files=\"/content/drive/MyDrive/Indicium/OLIVES_train_seed42.parquet\")['train']\n",
        "raw_val_data = load_dataset(\"parquet\", data_files=\"/content/drive/MyDrive/Indicium/OLIVES_val_seed42.parquet\")['train']\n",
        "raw_test_data = load_dataset(\"parquet\", data_files=\"/content/drive/MyDrive/Indicium/OLIVES_test_seed42.parquet\")['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wBRrPPOUyVkW"
      },
      "outputs": [],
      "source": [
        "print(raw_train_data)\n",
        "print(raw_val_data)\n",
        "print(raw_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF2qF8QCDikn",
        "outputId": "a687a7b0-61a8-4fde-dbb3-21193766dbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 14247\n",
            "Test size: 1568\n",
            "Validation size: 1654\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train size: {len(raw_train_data)}\")\n",
        "print(f\"Test size: {len(raw_test_data)}\")\n",
        "print(f\"Validation size: {len(raw_val_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qboAqTgiXdQY",
        "outputId": "7a8771f0-32ca-48a7-819b-15e607a74ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train disease label counts:\n",
            "Counter({1.0: 7975, 0.0: 6272})\n",
            "\n",
            "Validation disease label counts:\n",
            "Counter({1.0: 968, 0.0: 686})\n",
            "\n",
            "Test disease label counts:\n",
            "Counter({0.0: 784, 1.0: 784})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Get frequency of disease labels in each class\n",
        "train_label_counts = Counter(raw_train_data['Disease Label'])\n",
        "print(\"\\nTrain disease label counts:\")\n",
        "print(train_label_counts)\n",
        "\n",
        "val_label_counts = Counter(raw_val_data['Disease Label'])\n",
        "print(\"\\nValidation disease label counts:\")\n",
        "print(val_label_counts)\n",
        "\n",
        "test_label_counts = Counter(raw_test_data['Disease Label'])\n",
        "print(\"\\nTest disease label counts:\")\n",
        "print(test_label_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCB65s9W_HYg"
      },
      "source": [
        "# Preprocess the data\n",
        "This includes converting the images to RGB and applying ResNet50's standard preprocessing and one-hot encoding the biomarkers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPYpvuZoFDiz"
      },
      "outputs": [],
      "source": [
        "# Define biomarker fields\n",
        "biomarker_fields = [\n",
        "    \"Atrophy / thinning of retinal layers\",\n",
        "    \"Disruption of EZ\",\n",
        "    \"DRIL\",\n",
        "    \"IR hemorrhages\",\n",
        "    \"IR HRF\",\n",
        "    \"Partially attached vitreous face\",\n",
        "    \"Fully attached vitreous face\",\n",
        "    \"Preretinal tissue/hemorrhage\",\n",
        "    \"Vitreous debris\",\n",
        "    \"VMT\",\n",
        "    \"DRT/ME\",\n",
        "    \"Fluid (IRF)\",\n",
        "    \"Fluid (SRF)\",\n",
        "    \"Disruption of RPE\",\n",
        "    \"PED (serous)\",\n",
        "    \"SHRM\"\n",
        "]\n",
        "\n",
        "import io\n",
        "\n",
        "\n",
        "# Define transforms for validation and test datasets\n",
        "resnet_transform = transforms.Compose([\n",
        "    transforms.Resize(256),                        # Resize shorter side to 256\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB\n",
        "    transforms.ToTensor(),                 # Converts to [C, H, W] in range [0, 1]\n",
        "    transforms.Normalize(                  # Standard ImageNet normalization\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Define transforms for the training data.\n",
        "# Here we use the standard ResNet transform but apply random augmentations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15),  # ±15% brightness and contrast\n",
        "    transforms.RandomHorizontalFlip(p=0.5),                # 50% horizontal flip\n",
        "    transforms.RandomRotation(degrees=8),                  # ±8° rotation\n",
        "    transforms.RandomResizedCrop(224,                      # ResNet expects 224x224\n",
        "                                 scale=(0.25, 1.0),\n",
        "                                 ratio=(0.75, 1.33)),\n",
        "    transforms.Grayscale(num_output_channels=3),           # Convert grayscale to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "class RetinalDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, biomarker_fields=None, transform=None):\n",
        "        self.data = data\n",
        "        self.biomarker_fields = biomarker_fields\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        img_bytes = item['Image']['bytes']\n",
        "        img = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        biomarkers = [item[field] for field in self.biomarker_fields]\n",
        "        biomarkers = torch.tensor(biomarkers, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        return {\n",
        "            'image pixel values': img,\n",
        "            'biomarkers': biomarkers,\n",
        "            'label': item['Disease Label'],\n",
        "            'patient_id': item['Patient_ID']\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# Define the training and test torch Datasets\n",
        "processed_train_data = RetinalDataset(\n",
        "    data=raw_train_data,\n",
        "    biomarker_fields=biomarker_fields,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "\n",
        "processed_val_data = RetinalDataset(\n",
        "    data=raw_val_data,\n",
        "    biomarker_fields=biomarker_fields,\n",
        "    transform=resnet_transform\n",
        ")\n",
        "\n",
        "\n",
        "processed_test_data = RetinalDataset(\n",
        "    data=raw_test_data,\n",
        "    biomarker_fields=biomarker_fields,\n",
        "    transform=resnet_transform\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbEeWA-YR1e-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define a manual seeding function to consistently shuffle the datasets\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42) # Set anual seed to 42 by convention\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Wrap the datasets to a torch DataLoader to generate batches\n",
        "# Here, arrange into batches, shuffle the dataset and use\n",
        "# num_workers to maximize CPU cores for fetching.\n",
        "\n",
        "train_dataloader = DataLoader(processed_train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              num_workers=4,\n",
        "                              worker_init_fn=seed_worker,\n",
        "                              generator=g)\n",
        "\n",
        "validation_dataloader = DataLoader(processed_val_data,\n",
        "                                   batch_size=BATCH_SIZE,\n",
        "                                   shuffle=False,\n",
        "                                   num_workers=4,\n",
        "                                   worker_init_fn=seed_worker,\n",
        "                                   generator=g)\n",
        "\n",
        "# Used for model testing\n",
        "test_dataloader = DataLoader(processed_test_data, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuPSiJln20kX"
      },
      "source": [
        "# Define the model\n",
        "Here, we just concatenate the features learned from the biomarker and disease heads and return them for FAISS\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aljw2CSvX22L"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50, ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s8qebEqFWsms"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "class OCT_net(nn.Module):\n",
        "    def __init__(self, num_biomarkers=len(biomarker_fields), num_diseases=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # Load pre-trained ResNet50 and replace FC with identity\n",
        "        pre_trained_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        pre_trained_model.fc = nn.Identity()\n",
        "\n",
        "        # Freeze all layers in the backbone\n",
        "        for param in pre_trained_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.backbone = pre_trained_model\n",
        "        self.feature_dim = 2048  # Output of resnet50 with identity FC\n",
        "\n",
        "        # Biomarker regression head\n",
        "        self.biomarker_head = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_biomarkers)\n",
        "        )\n",
        "\n",
        "        # Disease classification head\n",
        "        self.disease_head = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_diseases)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_features=False, head=None):\n",
        "        x = self.backbone(x)  # Shape: (B, 2048)\n",
        "\n",
        "        biomarker_logits = self.biomarker_head(x)\n",
        "        disease_logits = self.disease_head(x)\n",
        "\n",
        "        if return_features:\n",
        "            biomarker_feats = self.biomarker_head[:-1](x)\n",
        "            disease_feats = self.disease_head[:-1](x)\n",
        "            combined = torch.cat([biomarker_feats, disease_feats], dim=1)\n",
        "            embedding = F.normalize(combined, dim=1, p=2)\n",
        "            return biomarker_logits, disease_logits, embedding\n",
        "\n",
        "        if head == 'biomarker':\n",
        "            return biomarker_logits\n",
        "        elif head == 'disease':\n",
        "            return disease_logits\n",
        "\n",
        "        return biomarker_logits, disease_logits\n",
        "\n",
        "\n",
        "model = OCT_net()\n",
        "#print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY1uCfJC5t1Q"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXQvu7qkCm8O"
      },
      "outputs": [],
      "source": [
        "# Check if using GPU\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "model = OCT_net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdza2pCvMmiB"
      },
      "outputs": [],
      "source": [
        "# For biomarkers (multi-label classification)\n",
        "biomarker_loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# For disease (multi-class classification)\n",
        "disease_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Use Adam as our optimizer\n",
        "LEARNING_RATE = 1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzTqaanYA-KL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define number of epochs and where to save model checkpoints\n",
        "num_epochs = 10\n",
        "date_entry = \"Jun_23\"\n",
        "checkpoint_dir = f\"/content/drive/MyDrive/Indicium/model_checkpoints/{date_entry}_augmentations_finetuning\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Define lists to save training and validation metrics.\n",
        "train_losses = []\n",
        "train_bio_losses = []        # biomarker loss for training\n",
        "train_disease_losses = []    # disease loss for training\n",
        "train_accuracies = []\n",
        "\n",
        "val_losses = []\n",
        "val_bio_losses = []          # biomarker loss for validation\n",
        "val_disease_losses = []      # disease loss for validation\n",
        "val_accuracies = []\n",
        "\n",
        "# Describes the main training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Define empty variables to save metrics for later\n",
        "    batch_train_losses = []\n",
        "    batch_train_bio_losses = []\n",
        "    batch_train_disease_losses = []\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # For each batch in the dataset\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "\n",
        "        # Access the images, biomarkers and labels.\n",
        "        # We convert these to the device we are using\n",
        "        # For biomarkers, we convert to float and for disease labels we convert to float 64\n",
        "        images = batch['image pixel values'].to(device)\n",
        "        biomarkers = batch['biomarkers'].float().to(device)\n",
        "        disease_labels = batch['label'].long().to(device)\n",
        "\n",
        "        # Reset the gradients to zero from previous batch\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the raw scores/logits from the biomarker and disease heades\n",
        "        biomarker_logits, disease_logits = model(images)\n",
        "\n",
        "        # Compute the losses\n",
        "        loss_bio = biomarker_loss_fn(biomarker_logits, biomarkers)\n",
        "        loss_disease = disease_loss_fn(disease_logits, disease_labels)\n",
        "        # Add the losses\n",
        "        total_loss = loss_bio + loss_disease\n",
        "\n",
        "        # Backpropagate the losses\n",
        "        total_loss.backward()\n",
        "        # Update the model's weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Save the total loss for this batch\n",
        "        batch_train_losses.append(total_loss.item())\n",
        "        batch_train_bio_losses.append(loss_bio.item())\n",
        "        batch_train_disease_losses.append(loss_disease.item())\n",
        "\n",
        "        # Get predicted class and determine if it is correct.\n",
        "        # Add to the total train and correct train variables\n",
        "        preds = disease_logits.argmax(dim=1)\n",
        "        correct_train += (preds == disease_labels).sum().item()\n",
        "        total_train += disease_labels.size(0)\n",
        "\n",
        "    # Compute the average training loss and accuracies\n",
        "    avg_train_loss = sum(batch_train_losses) / len(batch_train_losses)\n",
        "    avg_train_bio_loss = sum(batch_train_bio_losses) / len(batch_train_bio_losses)\n",
        "    avg_train_disease_loss = sum(batch_train_disease_losses) / len(batch_train_disease_losses)\n",
        "    train_accuracy = correct_train / total_train\n",
        "\n",
        "    # Save these metrics to plot later\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_bio_losses.append(avg_train_bio_loss)\n",
        "    train_disease_losses.append(avg_train_disease_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f} (Bio: {avg_train_bio_loss:.4f}, Disease: {avg_train_disease_loss:.4f}), Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval() # Make sure the model is in evaluating mode\n",
        "    batch_val_losses = []\n",
        "    batch_val_bio_losses = []\n",
        "    batch_val_disease_losses = []\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    # Tells model to compute no gradients when evaluating. Very similar to the training loop\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(validation_dataloader, desc=f\"Validating Epoch {epoch+1}\"):\n",
        "            images = batch['image pixel values'].to(device)\n",
        "            biomarkers = batch['biomarkers'].float().to(device)\n",
        "            disease_labels = batch['label'].long().to(device)\n",
        "\n",
        "            biomarker_logits, disease_logits = model(images)\n",
        "\n",
        "            loss_bio = biomarker_loss_fn(biomarker_logits, biomarkers)\n",
        "            loss_disease = disease_loss_fn(disease_logits, disease_labels)\n",
        "            total_loss = loss_bio + loss_disease\n",
        "\n",
        "            batch_val_losses.append(total_loss.item())\n",
        "            batch_val_bio_losses.append(loss_bio.item())\n",
        "            batch_val_disease_losses.append(loss_disease.item())\n",
        "\n",
        "            preds = disease_logits.argmax(dim=1)\n",
        "            correct_val += (preds == disease_labels).sum().item()\n",
        "            total_val += disease_labels.size(0)\n",
        "\n",
        "    # Compute the validation metrics and save for plotting later\n",
        "    avg_val_loss = sum(batch_val_losses) / len(batch_val_losses)\n",
        "    avg_val_bio_loss = sum(batch_val_bio_losses) / len(batch_val_bio_losses)\n",
        "    avg_val_disease_loss = sum(batch_val_disease_losses) / len(batch_val_disease_losses)\n",
        "    val_accuracy = correct_val / total_val\n",
        "\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_bio_losses.append(avg_val_bio_loss)\n",
        "    val_disease_losses.append(avg_val_disease_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Val Loss: {avg_val_loss:.4f} (Bio: {avg_val_bio_loss:.4f}, Disease: {avg_val_disease_loss:.4f}), Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Save checkpoint after each epoch\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}.pth\")\n",
        "\n",
        "    # Specify the epochs, the model's state dictionary (its gradients and weights)\n",
        "    # and other relevant metadata to our pre-defined checkpoint directory\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "\n",
        "        # Metadata\n",
        "        'optimizer_name': type(optimizer).__name__,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'num_epochs': num_epochs,\n",
        "\n",
        "        'train_losses': train_losses,\n",
        "        'train_bio_losses': train_bio_losses,\n",
        "        'train_disease_losses': train_disease_losses,\n",
        "\n",
        "        'val_losses': val_losses,\n",
        "        'val_bio_losses': val_bio_losses,\n",
        "        'val_disease_losses': val_disease_losses,\n",
        "\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_accuracies': val_accuracies,\n",
        "    }, checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55O_7GRMAu71"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0.8, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7MWt2wzOHbv"
      },
      "source": [
        "# Load trained model from disk\n",
        "Note: you need to run the cell that says \"Define Model\" still."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EsmkWg8qOGjZ"
      },
      "outputs": [],
      "source": [
        "# Check the device to either enable CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/Indicium/model_checkpoints/Jun_21_augmentations_finetuning/model_epoch_3.pth\"  # or whichever checkpoint we want\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "# Load the model's state dictionary, weights, gradients and optimizer\n",
        "model = OCT_net()\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# put model to device\n",
        "model.to(device)\n",
        "\n",
        "for param in model.backbone.layer2.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.backbone.layer3.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "for param in model.backbone.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "# Then, reinitialize the optimizer to include all parameters\n",
        "optimizer = torch.optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm5mOkn4RwQZ"
      },
      "source": [
        "Get learning curves for the entire model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RiGX6AEWRvsF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Specify the device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define lists for plotting later\n",
        "loaded_train_losses = []\n",
        "loaded_val_losses = []\n",
        "loaded_train_accuracies = []\n",
        "loaded_val_accuracies = []\n",
        "\n",
        "transfer_learning_epochs = 5  # Adjust based on checkpoints\n",
        "\n",
        "for epoch in range(1, transfer_learning_epochs + 1):\n",
        "    checkpoint_path = f\"/content/drive/MyDrive/Indicium/model_checkpoints/Jun_21_augmentations_transferlearning/model_epoch_{epoch}.pth\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Save the losses for plotting later\n",
        "    epoch_train_losses = checkpoint.get('train_losses', [])\n",
        "    epoch_val_losses = checkpoint.get('val_losses', [])\n",
        "    epoch_train_accuracies = checkpoint.get('train_accuracies', [])\n",
        "    epoch_val_accuracies = checkpoint.get('val_accuracies', [])\n",
        "\n",
        "    loaded_train_losses.append(epoch_train_losses[epoch - 1])\n",
        "    loaded_val_losses.append(epoch_val_losses[epoch - 1])\n",
        "    loaded_train_accuracies.append(epoch_train_accuracies[epoch - 1])\n",
        "    loaded_val_accuracies.append(epoch_val_accuracies[epoch - 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYE8c2AodJFx"
      },
      "source": [
        "Get losses from the finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-mqUFb40dIbS"
      },
      "outputs": [],
      "source": [
        "fine_tuning_epochs = 10  # Adjust based on checkpoints\n",
        "\n",
        "for epoch in range(1, fine_tuning_epochs + 1):\n",
        "    checkpoint_path = f\"/content/drive/MyDrive/Indicium/model_checkpoints/Jun_23_augmentations_finetuning/model_epoch_{epoch}.pth\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Save the losses for plotting later\n",
        "    epoch_train_losses = checkpoint.get('train_losses', [])\n",
        "    epoch_val_losses = checkpoint.get('val_losses', [])\n",
        "    epoch_train_accuracies = checkpoint.get('train_accuracies', [])\n",
        "    epoch_val_accuracies = checkpoint.get('val_accuracies', [])\n",
        "\n",
        "    loaded_train_losses.append(epoch_train_losses[epoch - 1])\n",
        "    loaded_val_losses.append(epoch_val_losses[epoch - 1])\n",
        "    loaded_train_accuracies.append(epoch_train_accuracies[epoch - 1])\n",
        "    loaded_val_accuracies.append(epoch_val_accuracies[epoch - 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSwIOKc7dA0z"
      },
      "outputs": [],
      "source": [
        "epochs_to_plot = range(1, transfer_learning_epochs + fine_tuning_epochs + 1)\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_to_plot, loaded_train_losses, 'b-', label='Training Loss')\n",
        "plt.plot(epochs_to_plot, loaded_val_losses, 'r-', label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0.3, 1)\n",
        "plt.legend()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_to_plot, loaded_train_accuracies, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs_to_plot, loaded_val_accuracies, 'r-', label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0.7, 1)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH6sa3m5DU81"
      },
      "source": [
        "# Inspect and run inference on an example:\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq8iWHHrEpb0",
        "outputId": "b5124957-a7a1-40b7-9370-9f3c92b9a483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random example index: 940\n",
            "True Disease Label: DME\n",
            "Predicted Disease Label: DR\n",
            "Disease Class Probabilities:\n",
            "  DR    : 52.23%\n",
            "  DME   : 47.77%\n",
            "\n",
            "Biomarker Probabilities:\n",
            "Atrophy / thinning of retinal layers | Predicted Probability: 0.502 | True Value: 0.000\n",
            "Disruption of EZ                    | Predicted Probability: 0.490 | True Value: 0.000\n",
            "DRIL                                | Predicted Probability: 0.492 | True Value: 0.000\n",
            "IR hemorrhages                      | Predicted Probability: 0.491 | True Value: 0.000\n",
            "IR HRF                              | Predicted Probability: 0.475 | True Value: 1.000\n",
            "Partially attached vitreous face    | Predicted Probability: 0.512 | True Value: 0.000\n",
            "Fully attached vitreous face        | Predicted Probability: 0.500 | True Value: 1.000\n",
            "Preretinal tissue/hemorrhage        | Predicted Probability: 0.509 | True Value: 0.000\n",
            "Vitreous debris                     | Predicted Probability: 0.502 | True Value: 1.000\n",
            "VMT                                 | Predicted Probability: 0.496 | True Value: 0.000\n",
            "DRT/ME                              | Predicted Probability: 0.520 | True Value: 1.000\n",
            "Fluid (IRF)                         | Predicted Probability: 0.501 | True Value: 1.000\n",
            "Fluid (SRF)                         | Predicted Probability: 0.506 | True Value: 0.000\n",
            "Disruption of RPE                   | Predicted Probability: 0.527 | True Value: 0.000\n",
            "PED (serous)                        | Predicted Probability: 0.499 | True Value: 0.000\n",
            "SHRM                                | Predicted Probability: 0.507 | True Value: 0.000\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "# Define the biomarkers and label for indexing\n",
        "label_map = {0: \"DR\", 1: \"DME\"}\n",
        "biomarker_fields = [\n",
        "    \"Atrophy / thinning of retinal layers\",\n",
        "    \"Disruption of EZ\",\n",
        "    \"DRIL\",\n",
        "    \"IR hemorrhages\",\n",
        "    \"IR HRF\",\n",
        "    \"Partially attached vitreous face\",\n",
        "    \"Fully attached vitreous face\",\n",
        "    \"Preretinal tissue/hemorrhage\",\n",
        "    \"Vitreous debris\",\n",
        "    \"VMT\",\n",
        "    \"DRT/ME\",\n",
        "    \"Fluid (IRF)\",\n",
        "    \"Fluid (SRF)\",\n",
        "    \"Disruption of RPE\",\n",
        "    \"PED (serous)\",\n",
        "    \"SHRM\"\n",
        "]\n",
        "\n",
        "# Directly access the dataset\n",
        "dataset = test_dataloader.dataset\n",
        "\n",
        "# Sample random index\n",
        "random_idx = random.randint(0, len(dataset) - 1)\n",
        "\n",
        "# Get a single example from dataset\n",
        "example = dataset[random_idx]\n",
        "\n",
        "# Get the image, biomarkers and labels. Use \"unsqueeze\" since the model expect a batch size of at least 1.\n",
        "image = example['image pixel values'].unsqueeze(0).to(device)\n",
        "true_biomarkers = example['biomarkers'].unsqueeze(0).to(device)\n",
        "true_label = torch.tensor(example['label']).long().unsqueeze(0).to(device)\n",
        "\n",
        "# Convert label if it's not a tensor\n",
        "if not isinstance(example['label'], torch.Tensor):\n",
        "    true_label = torch.tensor(example['label']).long().unsqueeze(0).to(device)\n",
        "else:\n",
        "    true_label = example['label'].long().unsqueeze(0).to(device)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# For inference, do not calculate gradients\n",
        "with torch.no_grad():\n",
        "  # Get the biomarker and disease label probabilities and the embedding\n",
        "    biomarker_logits, disease_logits, learned_features = model(image, return_features=True)\n",
        "\n",
        "# Apply sigmoid for the biomarkers since it is a multi-label classification task\n",
        "biomarker_probs = torch.sigmoid(biomarker_logits).squeeze().cpu().numpy()\n",
        "# Apply softmax for the disease labels, since it is a multi-class classification task\n",
        "disease_probs = F.softmax(disease_logits, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "# Get the predicted label and the true label\n",
        "predicted_label = disease_probs.argmax()\n",
        "true_label = true_label.item()\n",
        "\n",
        "# Print out the formatted results\n",
        "print(f\"Random example index: {random_idx}\")\n",
        "print(f\"True Disease Label: {label_map[true_label]}\")\n",
        "print(f\"Predicted Disease Label: {label_map[predicted_label]}\")\n",
        "print(\"Disease Class Probabilities:\")\n",
        "for cls_idx, prob in enumerate(disease_probs):\n",
        "    print(f\"  {label_map[cls_idx]:<6}: {prob * 100:.2f}%\")\n",
        "\n",
        "print(\"\\nBiomarker Probabilities:\")\n",
        "for name, prob, true_val in zip(biomarker_fields, biomarker_probs, true_biomarkers.squeeze().cpu().numpy()):\n",
        "    print(f\"{name:<35} | Predicted Probability: {prob:.3f} | True Value: {true_val:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmwgwZPQEsp"
      },
      "source": [
        "# Embed to FAISS database (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0SKx0L-QyH4"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Define lists to save to FAISS later\n",
        "all_features = []\n",
        "all_labels = []\n",
        "all_biomarkers = []\n",
        "\n",
        "# Here, we want to run inference and extract the learned features/embeddings.\n",
        "with torch.no_grad():\n",
        "  # Extract features from our test_dataloader dataset\n",
        "    for batch in tqdm(train_dataloader, desc=\"Extracting features @ training\"):\n",
        "        images = batch['image pixel values'].to(device)\n",
        "        labels = batch['label'].long().to(device)\n",
        "        biomarkers = batch['biomarkers'].float().to(device)\n",
        "\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Extract features just before disease head\n",
        "        _, _, features = model(images, return_features=True)  # shape: [B, 256]\n",
        "        features = features.cpu().numpy().astype(\"float32\")   # FAISS expects float32\n",
        "\n",
        "        all_features.append(features) # Features per sample\n",
        "        all_labels.extend(labels.cpu().numpy()) # Labels per sample\n",
        "        all_biomarkers.extend(biomarkers.cpu().numpy())  # Biomarkers per sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP20WDCWTxmz",
        "outputId": "de457bce-68e1-4a10-b0fb-1b17839d232a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14247, 256)\n"
          ]
        }
      ],
      "source": [
        "features_matrix = np.vstack(all_features)\n",
        "labels_array = np.array(all_labels)\n",
        "biomarkers_array = np.array(all_biomarkers)\n",
        "\n",
        "print(features_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2JEKgD9rBLq"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def normalize_vectors(vectors):\n",
        "    norms = np.linalg.norm(vectors, axis=1, keepdims=True)\n",
        "    return vectors / norms\n",
        "\n",
        "# Normalize your feature matrix\n",
        "features_matrix = normalize_vectors(features_matrix)\n",
        "\n",
        "d = features_matrix.shape[1]  # Feature size (2048)\n",
        "\n",
        "# Build FAISS index with L2 distance\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(features_matrix)\n",
        "\n",
        "save_date = \"Jun_23\"\n",
        "save_dir = f\"/content/drive/MyDrive/Indicium/FAISS_indexes/{save_date}_Jun23-model-finetuned\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save index\n",
        "faiss.write_index(index, f\"{save_dir}/oct_features.index\")\n",
        "\n",
        "# Save labels (for ID mapping)\n",
        "np.save(f\"{save_dir}/oct_labels.npy\", labels_array)\n",
        "np.save(f\"{save_dir}/oct_biomarkers.npy\", biomarkers_array)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVpvZwC6mM-i"
      },
      "source": [
        "# Load FAISS index from disk and run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ye521IWZeLSh"
      },
      "outputs": [],
      "source": [
        "labels_array = np.load(f\"{save_dir}/oct_labels.npy\")\n",
        "biomarkers_array = np.load(f\"{save_dir}/oct_biomarkers.npy\")\n",
        "index = faiss.read_index(f\"{save_dir}/oct_features.index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sF9ETpXnbgL"
      },
      "source": [
        "# Make a FAISS query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAMji7ovUnCO",
        "outputId": "fd132233-02bb-4739-ce50-cac045ccd586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random example index: 1130\n",
            "\n",
            "Query Results for True Label: 1\n",
            "\n",
            "[0.5096, 0.4903, 0.4885, 0.4733, 0.4887, 0.5045, 0.5041, 0.4905, 0.5095, 0.4744, 0.4992, 0.5151, 0.5005, 0.5243, 0.4894, 0.4963] \n",
            "\n",
            "Rank 1:\n",
            "  Index:       10080\n",
            "  Distance:    1.1553\n",
            "  Label:       1\n",
            "  Biomarkers:  [0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
            "----------------------------------------\n",
            "Rank 2:\n",
            "  Index:       5251\n",
            "  Distance:    1.1700\n",
            "  Label:       0\n",
            "  Biomarkers:  [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "----------------------------------------\n",
            "Rank 3:\n",
            "  Index:       12032\n",
            "  Distance:    1.1701\n",
            "  Label:       0\n",
            "  Biomarkers:  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "----------------------------------------\n",
            "Rank 4:\n",
            "  Index:       920\n",
            "  Distance:    1.1775\n",
            "  Label:       0\n",
            "  Biomarkers:  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "----------------------------------------\n",
            "Rank 5:\n",
            "  Index:       10865\n",
            "  Distance:    1.1824\n",
            "  Label:       1\n",
            "  Biomarkers:  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "label_map = {0: \"DR\", 1: \"DME\"}\n",
        "biomarker_fields = [\n",
        "    \"Atrophy / thinning of retinal layers\",\n",
        "    \"Disruption of EZ\",\n",
        "    \"DRIL\",\n",
        "    \"IR hemorrhages\",\n",
        "    \"IR HRF\",\n",
        "    \"Partially attached vitreous face\",\n",
        "    \"Fully attached vitreous face\",\n",
        "    \"Preretinal tissue/hemorrhage\",\n",
        "    \"Vitreous debris\",\n",
        "    \"VMT\",\n",
        "    \"DRT/ME\",\n",
        "    \"Fluid (IRF)\",\n",
        "    \"Fluid (SRF)\",\n",
        "    \"Disruption of RPE\",\n",
        "    \"PED (serous)\",\n",
        "    \"SHRM\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Query the image\n",
        "def get_biomarkers_and_features(model, img):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        biomarkers, _, feat = model(img.to(device), return_features=True)\n",
        "    return biomarkers.cpu(), feat.cpu().numpy().astype(\"float32\")\n",
        "\n",
        "\n",
        "\n",
        "# Directly access the dataset\n",
        "sample_dataset = test_dataloader.dataset\n",
        "\n",
        "# Sample random index\n",
        "random_idx = random.randint(0, len(sample_dataset) - 1)\n",
        "print(f\"Random example index: {random_idx}\")\n",
        "\n",
        "# Get a single example from dataset\n",
        "example = sample_dataset[random_idx]\n",
        "query_img = example['image pixel values'].unsqueeze(0).to(device)\n",
        "true_label = torch.tensor(example['label']).long().unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "# Get query biomarkers and normalized features\n",
        "query_biomarker_logits, query_feature = get_biomarkers_and_features(model, query_img)\n",
        "query_biomarkers = torch.sigmoid(query_biomarker_logits).squeeze().cpu().numpy()\n",
        "rounded_probs = np.round(query_biomarkers, 4).tolist()\n",
        "\n",
        "# Search FAISS, use k=5\n",
        "D, I = index.search(query_feature, k=5)\n",
        "topk_labels = labels_array[I[0]]\n",
        "topk_biomarkers = biomarkers_array[I[0]]\n",
        "topk_distances = D[0]\n",
        "\n",
        "# Pretty print results\n",
        "print(f\"\\nQuery Results for True Label: {true_label.item()}\\n\")\n",
        "print(\"[\" + \", \".join(f\"{x:.4f}\" for x in rounded_probs) + \"] \\n\")\n",
        "\n",
        "for rank, (idx, dist, label, biomarkers) in enumerate(zip(I[0], topk_distances, topk_labels, topk_biomarkers), 1):\n",
        "    print(f\"Rank {rank}:\")\n",
        "    print(f\"  Index:       {idx}\")\n",
        "    print(f\"  Distance:    {dist:.4f}\")\n",
        "    print(f\"  Label:       {label}\")\n",
        "    print(f\"  Biomarkers:  {biomarkers}\")\n",
        "    print(\"-\" * 40)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PVKQMv7n5RXC",
        "F82eGeoryGep",
        "TCB65s9W_HYg",
        "DuPSiJln20kX"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}